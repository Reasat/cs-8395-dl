2020-03-20-06-47-59
train.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 8
bottleneckFeatures: 1
brightness: None
contrast: None
cropSize: None
dir_lf: D:\Data\cs-8395-dl
dir_project: ..
encoder: resnet34
epoch: 100
folderData: assignment3\Training
folderPartition: train_test_org
lossWeight: [1.0, 1.0]
loss_weights: None
lr: 0.1
msg: trying to overfit on a section of a spleen
overrideLR: 1
path_kfold: D:\Projects\cs-8395-dl\Assignment_3_segmentation\partition\kfold_5.bin
resize: None
resume_from: None
to_ram: 0
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-03-20-06-47-59
epoch: 1/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 1/100, batch: 1/1, mean_loss 1.7024, mean_dice_loss: 0.9266, mean_ce: 0.7758
updating weights
{'loss_train': [1.7023966312408447], 'loss_d_train': [0.9266055226325989], 'loss_ce_train': [0.7757911682128906]}
epoch: 2/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 2/100, batch: 1/1, mean_loss 48499999637504.0000, mean_dice_loss: 1.0000, mean_ce: 48499999637504.0000
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0], 'loss_d_train': [0.9266055226325989, 0.9999879002571106], 'loss_ce_train': [0.7757911682128906, 48499999637504.0]}
epoch: 3/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 3/100, batch: 1/1, mean_loss 88984.5938, mean_dice_loss: 0.9243, mean_ce: 88983.6719
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0, 88984.59375], 'loss_d_train': [0.9266055226325989, 0.9999879002571106, 0.9242596626281738], 'loss_ce_train': [0.7757911682128906, 48499999637504.0, 88983.671875]}
epoch: 4/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 4/100, batch: 1/1, mean_loss 2.1903, mean_dice_loss: 0.9252, mean_ce: 1.2651
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0, 88984.59375, 2.1903035640716553], 'loss_d_train': [0.9266055226325989, 0.9999879002571106, 0.9242596626281738, 0.9251691699028015], 'loss_ce_train': [0.7757911682128906, 48499999637504.0, 88983.671875, 1.265134334564209]}
epoch: 5/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 5/100, batch: 1/1, mean_loss 1.5172, mean_dice_loss: 0.9277, mean_ce: 0.5895
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0, 88984.59375, 2.1903035640716553, 1.5171995162963867], 'loss_d_train': [0.9266055226325989, 0.9999879002571106, 0.9242596626281738, 0.9251691699028015, 0.9277222752571106], 'loss_ce_train': [0.7757911682128906, 48499999637504.0, 88983.671875, 1.265134334564209, 0.5894771814346313]}
epoch: 6/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 6/100, batch: 1/1, mean_loss 1.4843, mean_dice_loss: 0.9280, mean_ce: 0.5563
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0, 88984.59375, 2.1903035640716553, 1.5171995162963867, 1.4843066930770874], 'loss_d_train': [0.9266055226325989, 0.9999879002571106, 0.9242596626281738, 0.9251691699028015, 0.9277222752571106, 0.9280341863632202], 'loss_ce_train': [0.7757911682128906, 48499999637504.0, 88983.671875, 1.265134334564209, 0.5894771814346313, 0.5562725067138672]}
epoch: 7/100, training patient 0001
[128]
accumulating gradients, acc_step = 1
train >>> epoch: 7/100, batch: 1/1, mean_loss 1.4386, mean_dice_loss: 0.9285, mean_ce: 0.5100
updating weights
{'loss_train': [1.7023966312408447, 48499999637504.0, 88984.59375, 2.1903035640716553, 1.5171995162963867, 1.4843066930770874, 1.4385616779327393], 'loss_d_train': [0.9266055226325989, 0.9999879002571106, 0.9242596626281738, 0.9251691699028015, 0.9277222752571106, 0.9280341863632202, 0.9285157322883606], 'loss_ce_train': [0.7757911682128906, 48499999637504.0, 88983.671875, 1.265134334564209, 0.5894771814346313, 0.5562725067138672, 0.5100458860397339]}
epoch: 8/100, training patient 0001

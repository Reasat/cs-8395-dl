2020-01-14-04-54-25
train_hm.py
--------------------------------------------------------------------------------------------------------------------
alpha: 0.7
batchSize: 16
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: hm_net
epoch: 100
folderData: assignment1_data
gamma: 2
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-14-04-54-25
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
HM_Net(
  (conv1): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv2): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv3): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv4): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv5): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
tensor(1., device='cuda:0', dtype=torch.float64) tensor(2.8546, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 1/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 2/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 3/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 4/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 5/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 6/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)
train >>> epoch: 1/100, batch: 7/7, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64)
valid >>> epoch: 1/100, mean_loss: nan
tensor(1., device='cuda:0', dtype=torch.float64) tensor(nan, device='cuda:0', dtype=torch.float64, grad_fn=<MaxBackward1>)

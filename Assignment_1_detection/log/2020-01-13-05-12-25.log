2020-01-13-05-12-25
train.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 32
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: resnet18
epoch: 500
folderData: assignment1_data
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-13-05-12-25
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
ResNet18_flat_conv(
  (resnet18_fc_stripped): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (fc1): Linear(in_features=90112, out_features=2, bias=True)
)
torch.Size([32, 512, 11, 16])
train >>> epoch: 1/500, batch: 1/4, mean_loss: 2.9815
torch.Size([32, 512, 11, 16])
train >>> epoch: 1/500, batch: 2/4, mean_loss: 7056.1519
torch.Size([32, 512, 11, 16])
train >>> epoch: 1/500, batch: 3/4, mean_loss: 4854.8193
torch.Size([9, 512, 11, 16])
train >>> epoch: 1/500, batch: 4/4, mean_loss: 4225.5801
torch.Size([10, 512, 11, 16])
285252.90625
valid >>> epoch: 1/500, mean_loss: 285252.9062
criteria decreased from inf to 285252.9062, saving best model at D:\Data\cs-8395-dl\model\2020-01-13-05-12-25\2020-01-13-05-12-25_resnet18_best.pt
torch.Size([32, 512, 11, 16])
train >>> epoch: 2/500, batch: 1/4, mean_loss: 2383.3564
torch.Size([32, 512, 11, 16])
train >>> epoch: 2/500, batch: 2/4, mean_loss: 1939.5573
torch.Size([32, 512, 11, 16])
train >>> epoch: 2/500, batch: 3/4, mean_loss: 1481.5475
torch.Size([9, 512, 11, 16])
train >>> epoch: 2/500, batch: 4/4, mean_loss: 1162.3990
torch.Size([10, 512, 11, 16])
4020638.5
valid >>> epoch: 2/500, mean_loss: 4020638.5000
torch.Size([32, 512, 11, 16])
train >>> epoch: 3/500, batch: 1/4, mean_loss: 774.3669
torch.Size([32, 512, 11, 16])
train >>> epoch: 3/500, batch: 2/4, mean_loss: 767.4540
torch.Size([32, 512, 11, 16])
train >>> epoch: 3/500, batch: 3/4, mean_loss: 521.8615
torch.Size([9, 512, 11, 16])
train >>> epoch: 3/500, batch: 4/4, mean_loss: 498.3814
torch.Size([10, 512, 11, 16])
290198.65625
valid >>> epoch: 3/500, mean_loss: 290198.6562
torch.Size([32, 512, 11, 16])
train >>> epoch: 4/500, batch: 1/4, mean_loss: 161.4924
torch.Size([32, 512, 11, 16])
train >>> epoch: 4/500, batch: 2/4, mean_loss: 94.4148
torch.Size([32, 512, 11, 16])
train >>> epoch: 4/500, batch: 3/4, mean_loss: 95.0562
torch.Size([9, 512, 11, 16])
train >>> epoch: 4/500, batch: 4/4, mean_loss: 100.2309
torch.Size([10, 512, 11, 16])
9537.7861328125
valid >>> epoch: 4/500, mean_loss: 9537.7861
criteria decreased from 285252.9062 to 9537.7861, saving best model at D:\Data\cs-8395-dl\model\2020-01-13-05-12-25\2020-01-13-05-12-25_resnet18_best.pt
torch.Size([32, 512, 11, 16])
train >>> epoch: 5/500, batch: 1/4, mean_loss: 30.4169
torch.Size([32, 512, 11, 16])
train >>> epoch: 5/500, batch: 2/4, mean_loss: 51.7410
torch.Size([32, 512, 11, 16])
train >>> epoch: 5/500, batch: 3/4, mean_loss: 55.1022
torch.Size([9, 512, 11, 16])
train >>> epoch: 5/500, batch: 4/4, mean_loss: 44.7144
torch.Size([10, 512, 11, 16])
845.9197387695312
valid >>> epoch: 5/500, mean_loss: 845.9197
criteria decreased from 9537.7861 to 845.9197, saving best model at D:\Data\cs-8395-dl\model\2020-01-13-05-12-25\2020-01-13-05-12-25_resnet18_best.pt

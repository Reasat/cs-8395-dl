2020-01-14-19-30-38
train_hm.py
--------------------------------------------------------------------------------------------------------------------
agg: sum
alpha: 2.0
batchSize: 16
beta: 4
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: unet-vgg11
epoch: 200
folderData: assignment1_data
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-14-19-30-38
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
using pretrained (ImageNet) vgg11 as encoder
UNet11(
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): ReLU(inplace)
    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): ReLU(inplace)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (relu): ReLU(inplace)
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3s): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4s): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5s): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (center): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec5): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec4): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec3): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec2): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec1): ConvRelu(
    (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU(inplace)
  )
  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
)
tensor(74.9018, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(3329792.4426, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 1/7, mean_loss: 3329867.3443
tensor(246.7338, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(1130292.7852, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 2/7, mean_loss: 2230203.4316
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(104.4293, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 3/7, mean_loss: 1489980.8937
tensor(7663.0032, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 4/7, mean_loss: 1119401.4211
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 5/7, mean_loss: 897348.4684
tensor(10905.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 6/7, mean_loss: 749607.8975
tensor(2321.0058, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 1/200, batch: 7/7, mean_loss: 642852.6273
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 1/200, mean_loss: 0.0004
criteria decreased from inf to 0.0004, saving best model at D:\Data\cs-8395-dl\model\2020-01-14-19-30-38\2020-01-14-19-30-38_unet-vgg11_best.pt
tensor(10315.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 1/7, mean_loss: 10315.5812
tensor(8841.9268, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 2/7, mean_loss: 9578.7540
tensor(7663.0032, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 3/7, mean_loss: 8940.1704
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 4/7, mean_loss: 8989.2922
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 5/7, mean_loss: 9077.7115
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 6/7, mean_loss: 9234.9013
tensor(2818.3642, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 2/200, batch: 7/7, mean_loss: 8318.2531
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 2/200, mean_loss: 0.0004
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 1/7, mean_loss: 10020.8503
tensor(7957.7341, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 2/7, mean_loss: 8989.2922
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 3/7, mean_loss: 9038.4140
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 4/7, mean_loss: 8841.9268
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 5/7, mean_loss: 8959.8191
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 6/7, mean_loss: 9136.6576
tensor(3149.9364, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 3/200, batch: 7/7, mean_loss: 8281.4118
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 3/200, mean_loss: 0.0004
tensor(8841.9268, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 1/7, mean_loss: 8841.9268
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 2/7, mean_loss: 8547.1959
tensor(11199.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 3/7, mean_loss: 9431.3885
tensor(10315.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 4/7, mean_loss: 9652.4367
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 5/7, mean_loss: 9431.3885
tensor(8841.9268, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 6/7, mean_loss: 9333.1449
tensor(2486.7919, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 4/200, batch: 7/7, mean_loss: 8355.0945
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 4/200, mean_loss: 0.0004
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 1/7, mean_loss: 9431.3885
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 2/7, mean_loss: 8841.9268
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 3/7, mean_loss: 9234.9013
tensor(7957.7341, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 4/7, mean_loss: 8915.6095
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 5/7, mean_loss: 8782.9806
tensor(11494.5048, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 6/7, mean_loss: 9234.9013
tensor(2818.3642, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 5/200, batch: 7/7, mean_loss: 8318.2531
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 5/200, mean_loss: 0.0004
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 1/7, mean_loss: 9136.6576
tensor(10905.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 2/7, mean_loss: 10020.8503
tensor(10610.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 3/7, mean_loss: 10217.3376
tensor(7368.2723, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 4/7, mean_loss: 9505.0713
tensor(7073.5414, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 5/7, mean_loss: 9018.7653
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 6/7, mean_loss: 9185.7795
tensor(2984.1503, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 6/200, batch: 7/7, mean_loss: 8299.8324
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 6/200, mean_loss: 0.0004
tensor(7368.2723, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 1/7, mean_loss: 7368.2723
tensor(8841.9268, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 2/7, mean_loss: 8105.0995
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 3/7, mean_loss: 8252.4650
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 4/7, mean_loss: 8547.1959
tensor(10315.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 5/7, mean_loss: 8900.8729
tensor(10905.0430, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 6/7, mean_loss: 9234.9013
tensor(2818.3642, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 7/200, batch: 7/7, mean_loss: 8318.2531
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 7/200, mean_loss: 0.0004
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 1/7, mean_loss: 8547.1959
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 2/7, mean_loss: 8841.9268
tensor(9136.6576, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 3/7, mean_loss: 8940.1704
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 4/7, mean_loss: 8768.2440
tensor(10315.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 5/7, mean_loss: 9077.7115
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 6/7, mean_loss: 9234.9013
tensor(2818.3642, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 8/200, batch: 7/7, mean_loss: 8318.2531
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 8/200, mean_loss: 0.0004
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 1/7, mean_loss: 8252.4650
tensor(10610.3121, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 2/7, mean_loss: 9431.3885
tensor(11199.7739, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 3/7, mean_loss: 10020.8503
tensor(8252.4650, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 4/7, mean_loss: 9578.7540
tensor(8841.9268, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 5/7, mean_loss: 9431.3885
tensor(7368.2723, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 6/7, mean_loss: 9087.5358
tensor(3315.7225, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 9/200, batch: 7/7, mean_loss: 8262.9911
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)
valid >>> epoch: 9/200, mean_loss: 0.0004
tensor(10020.8503, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 1/7, mean_loss: 10020.8503
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 2/7, mean_loss: 9284.0231
tensor(9431.3885, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 3/7, mean_loss: 9333.1449
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 4/7, mean_loss: 9136.6576
tensor(8547.1959, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 5/7, mean_loss: 9018.7653
tensor(10315.5812, device='cuda:0', dtype=torch.float64,
       grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 6/7, mean_loss: 9234.9013
tensor(2818.3642, device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>) tensor(0., device='cuda:0', dtype=torch.float64, grad_fn=<SumBackward0>)
train >>> epoch: 10/200, batch: 7/7, mean_loss: 8318.2531
tensor(2947.3089, device='cuda:0', dtype=torch.float64) tensor(0., device='cuda:0', dtype=torch.float64)

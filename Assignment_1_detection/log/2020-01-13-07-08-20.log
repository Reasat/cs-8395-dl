2020-01-13-07-08-20
train_hm.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 8
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: hm_net
epoch: 300
folderData: assignment1_data
lr: 0.01
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-13-07-08-20
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
HM_Net(
  (conv1): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv2): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv3): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv4): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv5): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
train >>> epoch: 1/300, batch: 1/14, mean_loss: 308739.9826
train >>> epoch: 1/300, batch: 2/14, mean_loss: 302576.0600
train >>> epoch: 1/300, batch: 3/14, mean_loss: 296304.2641
train >>> epoch: 1/300, batch: 4/14, mean_loss: 290248.3623
train >>> epoch: 1/300, batch: 5/14, mean_loss: 284176.3601
train >>> epoch: 1/300, batch: 6/14, mean_loss: 278283.4639
train >>> epoch: 1/300, batch: 7/14, mean_loss: 272410.4353
train >>> epoch: 1/300, batch: 8/14, mean_loss: 266562.2399
train >>> epoch: 1/300, batch: 9/14, mean_loss: 260761.7512
train >>> epoch: 1/300, batch: 10/14, mean_loss: 254488.6685
train >>> epoch: 1/300, batch: 11/14, mean_loss: 249211.6631
train >>> epoch: 1/300, batch: 12/14, mean_loss: 244034.0803
train >>> epoch: 1/300, batch: 13/14, mean_loss: 238934.7777
train >>> epoch: 1/300, batch: 14/14, mean_loss: 223374.3335
7477.484192141222
1969.5556282179857
valid >>> epoch: 1/300, mean_loss: 4723.5199
criteria decreased from inf to 4723.5199, saving best model at D:\Data\cs-8395-dl\model\2020-01-13-07-08-20\2020-01-13-07-08-20_hm_net_best.pt
train >>> epoch: 2/300, batch: 1/14, mean_loss: 160617.0122
train >>> epoch: 2/300, batch: 2/14, mean_loss: 156653.5541
train >>> epoch: 2/300, batch: 3/14, mean_loss: 152743.7745
train >>> epoch: 2/300, batch: 4/14, mean_loss: 148895.8196

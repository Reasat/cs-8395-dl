2020-01-14-06-06-46
train_hm.py
--------------------------------------------------------------------------------------------------------------------
alpha: 0.9
batchSize: 16
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: unet-vgg11
epoch: 100
folderData: assignment1_data
gamma: 2
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-14-06-06-46
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
using vanilla vgg11 as encoder
UNet11(
  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (encoder): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace)
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (4): ReLU(inplace)
    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace)
    (8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace)
    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (12): ReLU(inplace)
    (13): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (14): ReLU(inplace)
    (15): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (16): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (17): ReLU(inplace)
    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (19): ReLU(inplace)
    (20): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (relu): ReLU(inplace)
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3s): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4s): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5s): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (center): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec5): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec4): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(768, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(512, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec3): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(256, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec2): DecoderBlock(
    (block): Sequential(
      (0): ConvRelu(
        (conv): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
        (activation): ReLU(inplace)
      )
      (1): ConvTranspose2d(128, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))
      (2): ReLU(inplace)
    )
  )
  (dec1): ConvRelu(
    (conv): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (activation): ReLU(inplace)
  )
  (final): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))
)
train >>> epoch: 1/100, batch: 1/7, mean_loss: 0.2922
train >>> epoch: 1/100, batch: 2/7, mean_loss: 0.2741
train >>> epoch: 1/100, batch: 3/7, mean_loss: 0.2454
train >>> epoch: 1/100, batch: 4/7, mean_loss: 0.1443
train >>> epoch: 1/100, batch: 5/7, mean_loss: -0.0946
train >>> epoch: 1/100, batch: 6/7, mean_loss: -0.2549
train >>> epoch: 1/100, batch: 7/7, mean_loss: -0.3676
valid >>> epoch: 1/100, mean_loss: -1.0221
criteria decreased from inf to -1.0221, saving best model at D:\Data\cs-8395-dl\model\2020-01-14-06-06-46\2020-01-14-06-06-46_unet-vgg11_best.pt
train >>> epoch: 2/100, batch: 1/7, mean_loss: -1.0043
train >>> epoch: 2/100, batch: 2/7, mean_loss: -1.0106
train >>> epoch: 2/100, batch: 3/7, mean_loss: -1.0260
train >>> epoch: 2/100, batch: 4/7, mean_loss: -1.0241
train >>> epoch: 2/100, batch: 5/7, mean_loss: -1.0281
train >>> epoch: 2/100, batch: 6/7, mean_loss: -1.0272
train >>> epoch: 2/100, batch: 7/7, mean_loss: -1.0257
valid >>> epoch: 2/100, mean_loss: -1.0221
train >>> epoch: 3/100, batch: 1/7, mean_loss: -1.0222
train >>> epoch: 3/100, batch: 2/7, mean_loss: -1.0247
train >>> epoch: 3/100, batch: 3/7, mean_loss: -1.0310
train >>> epoch: 3/100, batch: 4/7, mean_loss: -1.0262
train >>> epoch: 3/100, batch: 5/7, mean_loss: -1.0241
train >>> epoch: 3/100, batch: 6/7, mean_loss: -1.0275
train >>> epoch: 3/100, batch: 7/7, mean_loss: -1.0255
valid >>> epoch: 3/100, mean_loss: -1.0221
train >>> epoch: 4/100, batch: 1/7, mean_loss: -1.0128
train >>> epoch: 4/100, batch: 2/7, mean_loss: -1.0122
train >>> epoch: 4/100, batch: 3/7, mean_loss: -1.0173
train >>> epoch: 4/100, batch: 4/7, mean_loss: -1.0258
train >>> epoch: 4/100, batch: 5/7, mean_loss: -1.0282
train >>> epoch: 4/100, batch: 6/7, mean_loss: -1.0274
train >>> epoch: 4/100, batch: 7/7, mean_loss: -1.0256
valid >>> epoch: 4/100, mean_loss: -1.0221
train >>> epoch: 5/100, batch: 1/7, mean_loss: -1.0330
train >>> epoch: 5/100, batch: 2/7, mean_loss: -1.0247
train >>> epoch: 5/100, batch: 3/7, mean_loss: -1.0237
train >>> epoch: 5/100, batch: 4/7, mean_loss: -1.0247
train >>> epoch: 5/100, batch: 5/7, mean_loss: -1.0229
train >>> epoch: 5/100, batch: 6/7, mean_loss: -1.0287
train >>> epoch: 5/100, batch: 7/7, mean_loss: -1.0247
valid >>> epoch: 5/100, mean_loss: -1.0221
train >>> epoch: 6/100, batch: 1/7, mean_loss: -1.0397
train >>> epoch: 6/100, batch: 2/7, mean_loss: -1.0278
train >>> epoch: 6/100, batch: 3/7, mean_loss: -1.0273
train >>> epoch: 6/100, batch: 4/7, mean_loss: -1.0208
train >>> epoch: 6/100, batch: 5/7, mean_loss: -1.0254
train >>> epoch: 6/100, batch: 6/7, mean_loss: -1.0260
train >>> epoch: 6/100, batch: 7/7, mean_loss: -1.0265
valid >>> epoch: 6/100, mean_loss: -1.0221
train >>> epoch: 7/100, batch: 1/7, mean_loss: -1.0195
train >>> epoch: 7/100, batch: 2/7, mean_loss: -1.0204
train >>> epoch: 7/100, batch: 3/7, mean_loss: -1.0293
train >>> epoch: 7/100, batch: 4/7, mean_loss: -1.0248
train >>> epoch: 7/100, batch: 5/7, mean_loss: -1.0237
train >>> epoch: 7/100, batch: 6/7, mean_loss: -1.0262
train >>> epoch: 7/100, batch: 7/7, mean_loss: -1.0263
valid >>> epoch: 7/100, mean_loss: -1.0221
train >>> epoch: 8/100, batch: 1/7, mean_loss: -1.0164
train >>> epoch: 8/100, batch: 2/7, mean_loss: -1.0182
train >>> epoch: 8/100, batch: 3/7, mean_loss: -1.0309
train >>> epoch: 8/100, batch: 4/7, mean_loss: -1.0269
train >>> epoch: 8/100, batch: 5/7, mean_loss: -1.0238
train >>> epoch: 8/100, batch: 6/7, mean_loss: -1.0275
train >>> epoch: 8/100, batch: 7/7, mean_loss: -1.0255
valid >>> epoch: 8/100, mean_loss: -1.0221
train >>> epoch: 9/100, batch: 1/7, mean_loss: -1.0173
train >>> epoch: 9/100, batch: 2/7, mean_loss: -1.0162
train >>> epoch: 9/100, batch: 3/7, mean_loss: -1.0300
train >>> epoch: 9/100, batch: 4/7, mean_loss: -1.0325
train >>> epoch: 9/100, batch: 5/7, mean_loss: -1.0304
train >>> epoch: 9/100, batch: 6/7, mean_loss: -1.0284
train >>> epoch: 9/100, batch: 7/7, mean_loss: -1.0249
valid >>> epoch: 9/100, mean_loss: -1.0221
train >>> epoch: 10/100, batch: 1/7, mean_loss: -1.0066
train >>> epoch: 10/100, batch: 2/7, mean_loss: -1.0148
train >>> epoch: 10/100, batch: 3/7, mean_loss: -1.0136
train >>> epoch: 10/100, batch: 4/7, mean_loss: -1.0165
train >>> epoch: 10/100, batch: 5/7, mean_loss: -1.0232
train >>> epoch: 10/100, batch: 6/7, mean_loss: -1.0247
train >>> epoch: 10/100, batch: 7/7, mean_loss: -1.0273
valid >>> epoch: 10/100, mean_loss: -1.0221
train >>> epoch: 11/100, batch: 1/7, mean_loss: -1.0361
train >>> epoch: 11/100, batch: 2/7, mean_loss: -1.0475
train >>> epoch: 11/100, batch: 3/7, mean_loss: -1.0373
train >>> epoch: 11/100, batch: 4/7, mean_loss: -1.0333
train >>> epoch: 11/100, batch: 5/7, mean_loss: -1.0306
train >>> epoch: 11/100, batch: 6/7, mean_loss: -1.0256
train >>> epoch: 11/100, batch: 7/7, mean_loss: -1.0267
valid >>> epoch: 11/100, mean_loss: -1.0221
train >>> epoch: 12/100, batch: 1/7, mean_loss: -1.0119
train >>> epoch: 12/100, batch: 2/7, mean_loss: -1.0151
train >>> epoch: 12/100, batch: 3/7, mean_loss: -1.0134
train >>> epoch: 12/100, batch: 4/7, mean_loss: -1.0152
train >>> epoch: 12/100, batch: 5/7, mean_loss: -1.0251
train >>> epoch: 12/100, batch: 6/7, mean_loss: -1.0259
train >>> epoch: 12/100, batch: 7/7, mean_loss: -1.0265
valid >>> epoch: 12/100, mean_loss: -1.0221
train >>> epoch: 13/100, batch: 1/7, mean_loss: -1.0231
train >>> epoch: 13/100, batch: 2/7, mean_loss: -1.0200
train >>> epoch: 13/100, batch: 3/7, mean_loss: -1.0206
train >>> epoch: 13/100, batch: 4/7, mean_loss: -1.0206
train >>> epoch: 13/100, batch: 5/7, mean_loss: -1.0258
train >>> epoch: 13/100, batch: 6/7, mean_loss: -1.0248
train >>> epoch: 13/100, batch: 7/7, mean_loss: -1.0272
valid >>> epoch: 13/100, mean_loss: -1.0221
train >>> epoch: 14/100, batch: 1/7, mean_loss: -1.0155
train >>> epoch: 14/100, batch: 2/7, mean_loss: -1.0404
train >>> epoch: 14/100, batch: 3/7, mean_loss: -1.0287
train >>> epoch: 14/100, batch: 4/7, mean_loss: -1.0270
train >>> epoch: 14/100, batch: 5/7, mean_loss: -1.0266
train >>> epoch: 14/100, batch: 6/7, mean_loss: -1.0265
train >>> epoch: 14/100, batch: 7/7, mean_loss: -1.0262
valid >>> epoch: 14/100, mean_loss: -1.0221
train >>> epoch: 15/100, batch: 1/7, mean_loss: -1.0092
train >>> epoch: 15/100, batch: 2/7, mean_loss: -1.0240
train >>> epoch: 15/100, batch: 3/7, mean_loss: -1.0246
train >>> epoch: 15/100, batch: 4/7, mean_loss: -1.0352
train >>> epoch: 15/100, batch: 5/7, mean_loss: -1.0319
train >>> epoch: 15/100, batch: 6/7, mean_loss: -1.0271
train >>> epoch: 15/100, batch: 7/7, mean_loss: -1.0258
valid >>> epoch: 15/100, mean_loss: -1.0221
train >>> epoch: 16/100, batch: 1/7, mean_loss: -1.0218
train >>> epoch: 16/100, batch: 2/7, mean_loss: -1.0182
train >>> epoch: 16/100, batch: 3/7, mean_loss: -1.0334
train >>> epoch: 16/100, batch: 4/7, mean_loss: -1.0279
train >>> epoch: 16/100, batch: 5/7, mean_loss: -1.0269
train >>> epoch: 16/100, batch: 6/7, mean_loss: -1.0272
train >>> epoch: 16/100, batch: 7/7, mean_loss: -1.0257
valid >>> epoch: 16/100, mean_loss: -1.0221
train >>> epoch: 17/100, batch: 1/7, mean_loss: -1.0455
train >>> epoch: 17/100, batch: 2/7, mean_loss: -1.0292
train >>> epoch: 17/100, batch: 3/7, mean_loss: -1.0266
train >>> epoch: 17/100, batch: 4/7, mean_loss: -1.0249
train >>> epoch: 17/100, batch: 5/7, mean_loss: -1.0260
train >>> epoch: 17/100, batch: 6/7, mean_loss: -1.0272
train >>> epoch: 17/100, batch: 7/7, mean_loss: -1.0257
valid >>> epoch: 17/100, mean_loss: -1.0221
train >>> epoch: 18/100, batch: 1/7, mean_loss: -1.0227
train >>> epoch: 18/100, batch: 2/7, mean_loss: -1.0238
train >>> epoch: 18/100, batch: 3/7, mean_loss: -1.0370
train >>> epoch: 18/100, batch: 4/7, mean_loss: -1.0335
train >>> epoch: 18/100, batch: 5/7, mean_loss: -1.0291
train >>> epoch: 18/100, batch: 6/7, mean_loss: -1.0289
train >>> epoch: 18/100, batch: 7/7, mean_loss: -1.0246
valid >>> epoch: 18/100, mean_loss: -1.0221
train >>> epoch: 19/100, batch: 1/7, mean_loss: -1.0325
train >>> epoch: 19/100, batch: 2/7, mean_loss: -1.0388
train >>> epoch: 19/100, batch: 3/7, mean_loss: -1.0301
train >>> epoch: 19/100, batch: 4/7, mean_loss: -1.0283
train >>> epoch: 19/100, batch: 5/7, mean_loss: -1.0264
train >>> epoch: 19/100, batch: 6/7, mean_loss: -1.0263
train >>> epoch: 19/100, batch: 7/7, mean_loss: -1.0262
valid >>> epoch: 19/100, mean_loss: -1.0221
train >>> epoch: 20/100, batch: 1/7, mean_loss: -1.0204

2020-01-11-14-22-35
train.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 32
bottleneckFeatures: 1
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: resnet18
epoch: 100
folderData: assignment1_data
lr: 0.001
resume_from: D:\Data\cs-8395-dl\model\2020-01-11-13-31-47\2020-01-11-13-31-47_resnet18_best.pt
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35
loading images to RAM
loading images to RAM
freezing feature extracting layers
ResNet18(
  (resnet18): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
  (resnet18_fc_stripped): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (fc1): Linear(in_features=512, out_features=2, bias=True)
)
resuming training from D:\Data\cs-8395-dl\model\2020-01-11-13-31-47\2020-01-11-13-31-47_resnet18_best.pt
train >>> epoch: 94/193, batch: 1/4, mean_loss: 0.0189
train >>> epoch: 94/193, batch: 2/4, mean_loss: 0.0209
train >>> epoch: 94/193, batch: 3/4, mean_loss: 0.0265
train >>> epoch: 94/193, batch: 4/4, mean_loss: 0.0275
valid >>> epoch: 94/193, mean_loss: 0.0153
criteria decreased from 0.0158 to 0.0153, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 95/193, batch: 1/4, mean_loss: 0.0231
train >>> epoch: 95/193, batch: 2/4, mean_loss: 0.0249
train >>> epoch: 95/193, batch: 3/4, mean_loss: 0.0290
train >>> epoch: 95/193, batch: 4/4, mean_loss: 0.0350
valid >>> epoch: 95/193, mean_loss: 0.0191
train >>> epoch: 96/193, batch: 1/4, mean_loss: 0.0286
train >>> epoch: 96/193, batch: 2/4, mean_loss: 0.0271
train >>> epoch: 96/193, batch: 3/4, mean_loss: 0.0263
train >>> epoch: 96/193, batch: 4/4, mean_loss: 0.0466
valid >>> epoch: 96/193, mean_loss: 0.0150
criteria decreased from 0.0153 to 0.0150, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 97/193, batch: 1/4, mean_loss: 0.0248
train >>> epoch: 97/193, batch: 2/4, mean_loss: 0.0244
train >>> epoch: 97/193, batch: 3/4, mean_loss: 0.0354
train >>> epoch: 97/193, batch: 4/4, mean_loss: 0.0386
valid >>> epoch: 97/193, mean_loss: 0.0162
train >>> epoch: 98/193, batch: 1/4, mean_loss: 0.0153
train >>> epoch: 98/193, batch: 2/4, mean_loss: 0.0166
train >>> epoch: 98/193, batch: 3/4, mean_loss: 0.0220
train >>> epoch: 98/193, batch: 4/4, mean_loss: 0.0358
valid >>> epoch: 98/193, mean_loss: 0.0178
train >>> epoch: 99/193, batch: 1/4, mean_loss: 0.0215
train >>> epoch: 99/193, batch: 2/4, mean_loss: 0.0231
train >>> epoch: 99/193, batch: 3/4, mean_loss: 0.0291
train >>> epoch: 99/193, batch: 4/4, mean_loss: 0.0407
valid >>> epoch: 99/193, mean_loss: 0.0196
train >>> epoch: 100/193, batch: 1/4, mean_loss: 0.0182
train >>> epoch: 100/193, batch: 2/4, mean_loss: 0.0305
train >>> epoch: 100/193, batch: 3/4, mean_loss: 0.0366
train >>> epoch: 100/193, batch: 4/4, mean_loss: 0.0591
valid >>> epoch: 100/193, mean_loss: 0.0267
train >>> epoch: 101/193, batch: 1/4, mean_loss: 0.0257
train >>> epoch: 101/193, batch: 2/4, mean_loss: 0.0657
train >>> epoch: 101/193, batch: 3/4, mean_loss: 0.0881
train >>> epoch: 101/193, batch: 4/4, mean_loss: 0.0920
valid >>> epoch: 101/193, mean_loss: 0.0167
train >>> epoch: 102/193, batch: 1/4, mean_loss: 0.0303
train >>> epoch: 102/193, batch: 2/4, mean_loss: 0.0491
train >>> epoch: 102/193, batch: 3/4, mean_loss: 0.0836
train >>> epoch: 102/193, batch: 4/4, mean_loss: 0.0939
valid >>> epoch: 102/193, mean_loss: 0.0183
train >>> epoch: 103/193, batch: 1/4, mean_loss: 0.0273
train >>> epoch: 103/193, batch: 2/4, mean_loss: 0.0566
train >>> epoch: 103/193, batch: 3/4, mean_loss: 0.0644
train >>> epoch: 103/193, batch: 4/4, mean_loss: 0.0647
valid >>> epoch: 103/193, mean_loss: 0.0221
train >>> epoch: 104/193, batch: 1/4, mean_loss: 0.0336
train >>> epoch: 104/193, batch: 2/4, mean_loss: 0.0286
train >>> epoch: 104/193, batch: 3/4, mean_loss: 0.0315
train >>> epoch: 104/193, batch: 4/4, mean_loss: 0.0512
valid >>> epoch: 104/193, mean_loss: 0.0229
train >>> epoch: 105/193, batch: 1/4, mean_loss: 0.0222
train >>> epoch: 105/193, batch: 2/4, mean_loss: 0.0279
train >>> epoch: 105/193, batch: 3/4, mean_loss: 0.0252
train >>> epoch: 105/193, batch: 4/4, mean_loss: 0.0441
valid >>> epoch: 105/193, mean_loss: 0.0249
train >>> epoch: 106/193, batch: 1/4, mean_loss: 0.0457
train >>> epoch: 106/193, batch: 2/4, mean_loss: 0.0333
train >>> epoch: 106/193, batch: 3/4, mean_loss: 0.0391
train >>> epoch: 106/193, batch: 4/4, mean_loss: 0.0429
valid >>> epoch: 106/193, mean_loss: 0.0294
train >>> epoch: 107/193, batch: 1/4, mean_loss: 0.0300
train >>> epoch: 107/193, batch: 2/4, mean_loss: 0.0358
train >>> epoch: 107/193, batch: 3/4, mean_loss: 0.0319
train >>> epoch: 107/193, batch: 4/4, mean_loss: 0.0376
valid >>> epoch: 107/193, mean_loss: 0.0259
train >>> epoch: 108/193, batch: 1/4, mean_loss: 0.0481
train >>> epoch: 108/193, batch: 2/4, mean_loss: 0.0339
train >>> epoch: 108/193, batch: 3/4, mean_loss: 0.0307
train >>> epoch: 108/193, batch: 4/4, mean_loss: 0.0325
valid >>> epoch: 108/193, mean_loss: 0.0225
train >>> epoch: 109/193, batch: 1/4, mean_loss: 0.0277
train >>> epoch: 109/193, batch: 2/4, mean_loss: 0.0262
train >>> epoch: 109/193, batch: 3/4, mean_loss: 0.0232
train >>> epoch: 109/193, batch: 4/4, mean_loss: 0.0313
valid >>> epoch: 109/193, mean_loss: 0.0181
train >>> epoch: 110/193, batch: 1/4, mean_loss: 0.0340
train >>> epoch: 110/193, batch: 2/4, mean_loss: 0.0331
train >>> epoch: 110/193, batch: 3/4, mean_loss: 0.0276
train >>> epoch: 110/193, batch: 4/4, mean_loss: 0.0297
valid >>> epoch: 110/193, mean_loss: 0.0146
criteria decreased from 0.0150 to 0.0146, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 111/193, batch: 1/4, mean_loss: 0.0182
train >>> epoch: 111/193, batch: 2/4, mean_loss: 0.0277
train >>> epoch: 111/193, batch: 3/4, mean_loss: 0.0289
train >>> epoch: 111/193, batch: 4/4, mean_loss: 0.0307
valid >>> epoch: 111/193, mean_loss: 0.0141
criteria decreased from 0.0146 to 0.0141, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 112/193, batch: 1/4, mean_loss: 0.0241
train >>> epoch: 112/193, batch: 2/4, mean_loss: 0.0182
train >>> epoch: 112/193, batch: 3/4, mean_loss: 0.0186
train >>> epoch: 112/193, batch: 4/4, mean_loss: 0.0323
valid >>> epoch: 112/193, mean_loss: 0.0141
train >>> epoch: 113/193, batch: 1/4, mean_loss: 0.0206
train >>> epoch: 113/193, batch: 2/4, mean_loss: 0.0254
train >>> epoch: 113/193, batch: 3/4, mean_loss: 0.0254
train >>> epoch: 113/193, batch: 4/4, mean_loss: 0.0266
valid >>> epoch: 113/193, mean_loss: 0.0139
criteria decreased from 0.0141 to 0.0139, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 114/193, batch: 1/4, mean_loss: 0.0368
train >>> epoch: 114/193, batch: 2/4, mean_loss: 0.0269
train >>> epoch: 114/193, batch: 3/4, mean_loss: 0.0241
train >>> epoch: 114/193, batch: 4/4, mean_loss: 0.0337
valid >>> epoch: 114/193, mean_loss: 0.0183
train >>> epoch: 115/193, batch: 1/4, mean_loss: 0.0242
train >>> epoch: 115/193, batch: 2/4, mean_loss: 0.0276
train >>> epoch: 115/193, batch: 3/4, mean_loss: 0.0333
train >>> epoch: 115/193, batch: 4/4, mean_loss: 0.0383
valid >>> epoch: 115/193, mean_loss: 0.0178
train >>> epoch: 116/193, batch: 1/4, mean_loss: 0.0180
train >>> epoch: 116/193, batch: 2/4, mean_loss: 0.0205
train >>> epoch: 116/193, batch: 3/4, mean_loss: 0.0251
train >>> epoch: 116/193, batch: 4/4, mean_loss: 0.0310
valid >>> epoch: 116/193, mean_loss: 0.0187
train >>> epoch: 117/193, batch: 1/4, mean_loss: 0.0236
train >>> epoch: 117/193, batch: 2/4, mean_loss: 0.0381
train >>> epoch: 117/193, batch: 3/4, mean_loss: 0.0420
train >>> epoch: 117/193, batch: 4/4, mean_loss: 0.0459
valid >>> epoch: 117/193, mean_loss: 0.0332
train >>> epoch: 118/193, batch: 1/4, mean_loss: 0.0140
train >>> epoch: 118/193, batch: 2/4, mean_loss: 0.0822
train >>> epoch: 118/193, batch: 3/4, mean_loss: 0.0668
train >>> epoch: 118/193, batch: 4/4, mean_loss: 0.0620
valid >>> epoch: 118/193, mean_loss: 0.0156
train >>> epoch: 119/193, batch: 1/4, mean_loss: 0.0303
train >>> epoch: 119/193, batch: 2/4, mean_loss: 0.0296
train >>> epoch: 119/193, batch: 3/4, mean_loss: 0.0294
train >>> epoch: 119/193, batch: 4/4, mean_loss: 0.0278
valid >>> epoch: 119/193, mean_loss: 0.0147
train >>> epoch: 120/193, batch: 1/4, mean_loss: 0.0216
train >>> epoch: 120/193, batch: 2/4, mean_loss: 0.0299
train >>> epoch: 120/193, batch: 3/4, mean_loss: 0.0289
train >>> epoch: 120/193, batch: 4/4, mean_loss: 0.0298
valid >>> epoch: 120/193, mean_loss: 0.0163
train >>> epoch: 121/193, batch: 1/4, mean_loss: 0.0255
train >>> epoch: 121/193, batch: 2/4, mean_loss: 0.0328
train >>> epoch: 121/193, batch: 3/4, mean_loss: 0.0344
train >>> epoch: 121/193, batch: 4/4, mean_loss: 0.0381
valid >>> epoch: 121/193, mean_loss: 0.0135
criteria decreased from 0.0139 to 0.0135, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 122/193, batch: 1/4, mean_loss: 0.0259
train >>> epoch: 122/193, batch: 2/4, mean_loss: 0.0268
train >>> epoch: 122/193, batch: 3/4, mean_loss: 0.0333
train >>> epoch: 122/193, batch: 4/4, mean_loss: 0.0351
valid >>> epoch: 122/193, mean_loss: 0.0135
train >>> epoch: 123/193, batch: 1/4, mean_loss: 0.0242
train >>> epoch: 123/193, batch: 2/4, mean_loss: 0.0301
train >>> epoch: 123/193, batch: 3/4, mean_loss: 0.0280
train >>> epoch: 123/193, batch: 4/4, mean_loss: 0.0284
valid >>> epoch: 123/193, mean_loss: 0.0114
criteria decreased from 0.0135 to 0.0114, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 124/193, batch: 1/4, mean_loss: 0.0127
train >>> epoch: 124/193, batch: 2/4, mean_loss: 0.0133
train >>> epoch: 124/193, batch: 3/4, mean_loss: 0.0144
train >>> epoch: 124/193, batch: 4/4, mean_loss: 0.0193
valid >>> epoch: 124/193, mean_loss: 0.0188
train >>> epoch: 125/193, batch: 1/4, mean_loss: 0.0208
train >>> epoch: 125/193, batch: 2/4, mean_loss: 0.0189
train >>> epoch: 125/193, batch: 3/4, mean_loss: 0.0179
train >>> epoch: 125/193, batch: 4/4, mean_loss: 0.0303
valid >>> epoch: 125/193, mean_loss: 0.0149
train >>> epoch: 126/193, batch: 1/4, mean_loss: 0.0266
train >>> epoch: 126/193, batch: 2/4, mean_loss: 0.0266
train >>> epoch: 126/193, batch: 3/4, mean_loss: 0.0244
train >>> epoch: 126/193, batch: 4/4, mean_loss: 0.0263
valid >>> epoch: 126/193, mean_loss: 0.0129
train >>> epoch: 127/193, batch: 1/4, mean_loss: 0.0191
train >>> epoch: 127/193, batch: 2/4, mean_loss: 0.0200
train >>> epoch: 127/193, batch: 3/4, mean_loss: 0.0196
train >>> epoch: 127/193, batch: 4/4, mean_loss: 0.0213
valid >>> epoch: 127/193, mean_loss: 0.0193
train >>> epoch: 128/193, batch: 1/4, mean_loss: 0.0211
train >>> epoch: 128/193, batch: 2/4, mean_loss: 0.0281
train >>> epoch: 128/193, batch: 3/4, mean_loss: 0.0282
train >>> epoch: 128/193, batch: 4/4, mean_loss: 0.0282
valid >>> epoch: 128/193, mean_loss: 0.0155
train >>> epoch: 129/193, batch: 1/4, mean_loss: 0.0162
train >>> epoch: 129/193, batch: 2/4, mean_loss: 0.0209
train >>> epoch: 129/193, batch: 3/4, mean_loss: 0.0215
train >>> epoch: 129/193, batch: 4/4, mean_loss: 0.0243
valid >>> epoch: 129/193, mean_loss: 0.0119
train >>> epoch: 130/193, batch: 1/4, mean_loss: 0.0167
train >>> epoch: 130/193, batch: 2/4, mean_loss: 0.0175
train >>> epoch: 130/193, batch: 3/4, mean_loss: 0.0191
train >>> epoch: 130/193, batch: 4/4, mean_loss: 0.0272
valid >>> epoch: 130/193, mean_loss: 0.0169
train >>> epoch: 131/193, batch: 1/4, mean_loss: 0.0302
train >>> epoch: 131/193, batch: 2/4, mean_loss: 0.0304
train >>> epoch: 131/193, batch: 3/4, mean_loss: 0.0271
train >>> epoch: 131/193, batch: 4/4, mean_loss: 0.0309
valid >>> epoch: 131/193, mean_loss: 0.0121
train >>> epoch: 132/193, batch: 1/4, mean_loss: 0.0139
train >>> epoch: 132/193, batch: 2/4, mean_loss: 0.0301
train >>> epoch: 132/193, batch: 3/4, mean_loss: 0.0283
train >>> epoch: 132/193, batch: 4/4, mean_loss: 0.0317
valid >>> epoch: 132/193, mean_loss: 0.0116
train >>> epoch: 133/193, batch: 1/4, mean_loss: 0.0156
train >>> epoch: 133/193, batch: 2/4, mean_loss: 0.0185
train >>> epoch: 133/193, batch: 3/4, mean_loss: 0.0167
train >>> epoch: 133/193, batch: 4/4, mean_loss: 0.0205
valid >>> epoch: 133/193, mean_loss: 0.0129
train >>> epoch: 134/193, batch: 1/4, mean_loss: 0.0240
train >>> epoch: 134/193, batch: 2/4, mean_loss: 0.0183
train >>> epoch: 134/193, batch: 3/4, mean_loss: 0.0197
train >>> epoch: 134/193, batch: 4/4, mean_loss: 0.0259
valid >>> epoch: 134/193, mean_loss: 0.0105
criteria decreased from 0.0114 to 0.0105, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 135/193, batch: 1/4, mean_loss: 0.0141
train >>> epoch: 135/193, batch: 2/4, mean_loss: 0.0140
train >>> epoch: 135/193, batch: 3/4, mean_loss: 0.0144
train >>> epoch: 135/193, batch: 4/4, mean_loss: 0.0146
valid >>> epoch: 135/193, mean_loss: 0.0115
train >>> epoch: 136/193, batch: 1/4, mean_loss: 0.0259
train >>> epoch: 136/193, batch: 2/4, mean_loss: 0.0223
train >>> epoch: 136/193, batch: 3/4, mean_loss: 0.0190
train >>> epoch: 136/193, batch: 4/4, mean_loss: 0.0472
valid >>> epoch: 136/193, mean_loss: 0.0144
train >>> epoch: 137/193, batch: 1/4, mean_loss: 0.0210
train >>> epoch: 137/193, batch: 2/4, mean_loss: 0.0247
train >>> epoch: 137/193, batch: 3/4, mean_loss: 0.0298
train >>> epoch: 137/193, batch: 4/4, mean_loss: 0.0336
valid >>> epoch: 137/193, mean_loss: 0.0120
train >>> epoch: 138/193, batch: 1/4, mean_loss: 0.0238
train >>> epoch: 138/193, batch: 2/4, mean_loss: 0.0327
train >>> epoch: 138/193, batch: 3/4, mean_loss: 0.0353
train >>> epoch: 138/193, batch: 4/4, mean_loss: 0.0310
valid >>> epoch: 138/193, mean_loss: 0.0134
train >>> epoch: 139/193, batch: 1/4, mean_loss: 0.0160
train >>> epoch: 139/193, batch: 2/4, mean_loss: 0.0187
train >>> epoch: 139/193, batch: 3/4, mean_loss: 0.0237
train >>> epoch: 139/193, batch: 4/4, mean_loss: 0.0309
valid >>> epoch: 139/193, mean_loss: 0.0158
train >>> epoch: 140/193, batch: 1/4, mean_loss: 0.0494
train >>> epoch: 140/193, batch: 2/4, mean_loss: 0.0368
train >>> epoch: 140/193, batch: 3/4, mean_loss: 0.0331
train >>> epoch: 140/193, batch: 4/4, mean_loss: 0.0363
valid >>> epoch: 140/193, mean_loss: 0.0134
train >>> epoch: 141/193, batch: 1/4, mean_loss: 0.0352
train >>> epoch: 141/193, batch: 2/4, mean_loss: 0.0278
train >>> epoch: 141/193, batch: 3/4, mean_loss: 0.0243
train >>> epoch: 141/193, batch: 4/4, mean_loss: 0.0238
valid >>> epoch: 141/193, mean_loss: 0.0106
train >>> epoch: 142/193, batch: 1/4, mean_loss: 0.0160
train >>> epoch: 142/193, batch: 2/4, mean_loss: 0.0258
train >>> epoch: 142/193, batch: 3/4, mean_loss: 0.0210
train >>> epoch: 142/193, batch: 4/4, mean_loss: 0.0222
valid >>> epoch: 142/193, mean_loss: 0.0095
criteria decreased from 0.0105 to 0.0095, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 143/193, batch: 1/4, mean_loss: 0.0127
train >>> epoch: 143/193, batch: 2/4, mean_loss: 0.0172
train >>> epoch: 143/193, batch: 3/4, mean_loss: 0.0165
train >>> epoch: 143/193, batch: 4/4, mean_loss: 0.0201
valid >>> epoch: 143/193, mean_loss: 0.0184
train >>> epoch: 144/193, batch: 1/4, mean_loss: 0.0168
train >>> epoch: 144/193, batch: 2/4, mean_loss: 0.0236
train >>> epoch: 144/193, batch: 3/4, mean_loss: 0.0205
train >>> epoch: 144/193, batch: 4/4, mean_loss: 0.0316
valid >>> epoch: 144/193, mean_loss: 0.0116
train >>> epoch: 145/193, batch: 1/4, mean_loss: 0.0245
train >>> epoch: 145/193, batch: 2/4, mean_loss: 0.0277
train >>> epoch: 145/193, batch: 3/4, mean_loss: 0.0284
train >>> epoch: 145/193, batch: 4/4, mean_loss: 0.0332
valid >>> epoch: 145/193, mean_loss: 0.0191
train >>> epoch: 146/193, batch: 1/4, mean_loss: 0.0142
train >>> epoch: 146/193, batch: 2/4, mean_loss: 0.0195
train >>> epoch: 146/193, batch: 3/4, mean_loss: 0.0373
train >>> epoch: 146/193, batch: 4/4, mean_loss: 0.0348
valid >>> epoch: 146/193, mean_loss: 0.0121
train >>> epoch: 147/193, batch: 1/4, mean_loss: 0.0177
train >>> epoch: 147/193, batch: 2/4, mean_loss: 0.0254
train >>> epoch: 147/193, batch: 3/4, mean_loss: 0.0331
train >>> epoch: 147/193, batch: 4/4, mean_loss: 0.0500
valid >>> epoch: 147/193, mean_loss: 0.0182
train >>> epoch: 148/193, batch: 1/4, mean_loss: 0.0189
train >>> epoch: 148/193, batch: 2/4, mean_loss: 0.0455
train >>> epoch: 148/193, batch: 3/4, mean_loss: 0.0689
train >>> epoch: 148/193, batch: 4/4, mean_loss: 0.0607
valid >>> epoch: 148/193, mean_loss: 0.0118
train >>> epoch: 149/193, batch: 1/4, mean_loss: 0.0140
train >>> epoch: 149/193, batch: 2/4, mean_loss: 0.0313
train >>> epoch: 149/193, batch: 3/4, mean_loss: 0.0379
train >>> epoch: 149/193, batch: 4/4, mean_loss: 0.0494
valid >>> epoch: 149/193, mean_loss: 0.0094
criteria decreased from 0.0095 to 0.0094, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 150/193, batch: 1/4, mean_loss: 0.0169
train >>> epoch: 150/193, batch: 2/4, mean_loss: 0.0289
train >>> epoch: 150/193, batch: 3/4, mean_loss: 0.0297
train >>> epoch: 150/193, batch: 4/4, mean_loss: 0.0458
valid >>> epoch: 150/193, mean_loss: 0.0088
criteria decreased from 0.0094 to 0.0088, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 151/193, batch: 1/4, mean_loss: 0.0120
train >>> epoch: 151/193, batch: 2/4, mean_loss: 0.0163
train >>> epoch: 151/193, batch: 3/4, mean_loss: 0.0350
train >>> epoch: 151/193, batch: 4/4, mean_loss: 0.0703
valid >>> epoch: 151/193, mean_loss: 0.0129
train >>> epoch: 152/193, batch: 1/4, mean_loss: 0.0128
train >>> epoch: 152/193, batch: 2/4, mean_loss: 0.0463
train >>> epoch: 152/193, batch: 3/4, mean_loss: 0.0611
train >>> epoch: 152/193, batch: 4/4, mean_loss: 0.0522
valid >>> epoch: 152/193, mean_loss: 0.0165
train >>> epoch: 153/193, batch: 1/4, mean_loss: 0.0318
train >>> epoch: 153/193, batch: 2/4, mean_loss: 0.0242
train >>> epoch: 153/193, batch: 3/4, mean_loss: 0.0310
train >>> epoch: 153/193, batch: 4/4, mean_loss: 0.0453
valid >>> epoch: 153/193, mean_loss: 0.0167
train >>> epoch: 154/193, batch: 1/4, mean_loss: 0.0128
train >>> epoch: 154/193, batch: 2/4, mean_loss: 0.0125
train >>> epoch: 154/193, batch: 3/4, mean_loss: 0.0222
train >>> epoch: 154/193, batch: 4/4, mean_loss: 0.0318
valid >>> epoch: 154/193, mean_loss: 0.0126
train >>> epoch: 155/193, batch: 1/4, mean_loss: 0.0218
train >>> epoch: 155/193, batch: 2/4, mean_loss: 0.0193
train >>> epoch: 155/193, batch: 3/4, mean_loss: 0.0229
train >>> epoch: 155/193, batch: 4/4, mean_loss: 0.0326
valid >>> epoch: 155/193, mean_loss: 0.0164
train >>> epoch: 156/193, batch: 1/4, mean_loss: 0.0158
train >>> epoch: 156/193, batch: 2/4, mean_loss: 0.0221
train >>> epoch: 156/193, batch: 3/4, mean_loss: 0.0249
train >>> epoch: 156/193, batch: 4/4, mean_loss: 0.0438
valid >>> epoch: 156/193, mean_loss: 0.0388
train >>> epoch: 157/193, batch: 1/4, mean_loss: 0.0653
train >>> epoch: 157/193, batch: 2/4, mean_loss: 0.0620
train >>> epoch: 157/193, batch: 3/4, mean_loss: 0.0458
train >>> epoch: 157/193, batch: 4/4, mean_loss: 0.0535
valid >>> epoch: 157/193, mean_loss: 0.0142
train >>> epoch: 158/193, batch: 1/4, mean_loss: 0.0184
train >>> epoch: 158/193, batch: 2/4, mean_loss: 0.0346
train >>> epoch: 158/193, batch: 3/4, mean_loss: 0.0273
train >>> epoch: 158/193, batch: 4/4, mean_loss: 0.0373
valid >>> epoch: 158/193, mean_loss: 0.0138
train >>> epoch: 159/193, batch: 1/4, mean_loss: 0.0190
train >>> epoch: 159/193, batch: 2/4, mean_loss: 0.0360
train >>> epoch: 159/193, batch: 3/4, mean_loss: 0.0327
train >>> epoch: 159/193, batch: 4/4, mean_loss: 0.0358
valid >>> epoch: 159/193, mean_loss: 0.0231
train >>> epoch: 160/193, batch: 1/4, mean_loss: 0.0383
train >>> epoch: 160/193, batch: 2/4, mean_loss: 0.0343
train >>> epoch: 160/193, batch: 3/4, mean_loss: 0.0347
train >>> epoch: 160/193, batch: 4/4, mean_loss: 0.0438
valid >>> epoch: 160/193, mean_loss: 0.0100
train >>> epoch: 161/193, batch: 1/4, mean_loss: 0.0106
train >>> epoch: 161/193, batch: 2/4, mean_loss: 0.0135
train >>> epoch: 161/193, batch: 3/4, mean_loss: 0.0141
train >>> epoch: 161/193, batch: 4/4, mean_loss: 0.0209
valid >>> epoch: 161/193, mean_loss: 0.0146
train >>> epoch: 162/193, batch: 1/4, mean_loss: 0.0151
train >>> epoch: 162/193, batch: 2/4, mean_loss: 0.0158
train >>> epoch: 162/193, batch: 3/4, mean_loss: 0.0187
train >>> epoch: 162/193, batch: 4/4, mean_loss: 0.0312
valid >>> epoch: 162/193, mean_loss: 0.0219
train >>> epoch: 163/193, batch: 1/4, mean_loss: 0.0444
train >>> epoch: 163/193, batch: 2/4, mean_loss: 0.0458
train >>> epoch: 163/193, batch: 3/4, mean_loss: 0.0426
train >>> epoch: 163/193, batch: 4/4, mean_loss: 0.0471
valid >>> epoch: 163/193, mean_loss: 0.0128
train >>> epoch: 164/193, batch: 1/4, mean_loss: 0.0131
train >>> epoch: 164/193, batch: 2/4, mean_loss: 0.0242
train >>> epoch: 164/193, batch: 3/4, mean_loss: 0.0189
train >>> epoch: 164/193, batch: 4/4, mean_loss: 0.0400
valid >>> epoch: 164/193, mean_loss: 0.0075
criteria decreased from 0.0088 to 0.0075, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-14-22-35\2020-01-11-14-22-35_resnet18_best.pt
train >>> epoch: 165/193, batch: 1/4, mean_loss: 0.0150
train >>> epoch: 165/193, batch: 2/4, mean_loss: 0.0116
train >>> epoch: 165/193, batch: 3/4, mean_loss: 0.0143
train >>> epoch: 165/193, batch: 4/4, mean_loss: 0.0248
valid >>> epoch: 165/193, mean_loss: 0.0139
train >>> epoch: 166/193, batch: 1/4, mean_loss: 0.0242
train >>> epoch: 166/193, batch: 2/4, mean_loss: 0.0233
train >>> epoch: 166/193, batch: 3/4, mean_loss: 0.0253
train >>> epoch: 166/193, batch: 4/4, mean_loss: 0.0258
valid >>> epoch: 166/193, mean_loss: 0.0140
train >>> epoch: 167/193, batch: 1/4, mean_loss: 0.0200
train >>> epoch: 167/193, batch: 2/4, mean_loss: 0.0236
train >>> epoch: 167/193, batch: 3/4, mean_loss: 0.0303
train >>> epoch: 167/193, batch: 4/4, mean_loss: 0.0357
valid >>> epoch: 167/193, mean_loss: 0.0091
train >>> epoch: 168/193, batch: 1/4, mean_loss: 0.0148
train >>> epoch: 168/193, batch: 2/4, mean_loss: 0.0240
train >>> epoch: 168/193, batch: 3/4, mean_loss: 0.0243
train >>> epoch: 168/193, batch: 4/4, mean_loss: 0.0250
valid >>> epoch: 168/193, mean_loss: 0.0103
train >>> epoch: 169/193, batch: 1/4, mean_loss: 0.0143
train >>> epoch: 169/193, batch: 2/4, mean_loss: 0.0183
train >>> epoch: 169/193, batch: 3/4, mean_loss: 0.0185
train >>> epoch: 169/193, batch: 4/4, mean_loss: 0.0218
valid >>> epoch: 169/193, mean_loss: 0.0101
train >>> epoch: 170/193, batch: 1/4, mean_loss: 0.0254
train >>> epoch: 170/193, batch: 2/4, mean_loss: 0.0191
train >>> epoch: 170/193, batch: 3/4, mean_loss: 0.0188
train >>> epoch: 170/193, batch: 4/4, mean_loss: 0.0296
valid >>> epoch: 170/193, mean_loss: 0.0101
train >>> epoch: 171/193, batch: 1/4, mean_loss: 0.0193
train >>> epoch: 171/193, batch: 2/4, mean_loss: 0.0172
train >>> epoch: 171/193, batch: 3/4, mean_loss: 0.0193
train >>> epoch: 171/193, batch: 4/4, mean_loss: 0.0233

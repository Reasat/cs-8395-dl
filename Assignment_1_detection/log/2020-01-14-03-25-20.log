2020-01-14-03-25-20
train_hm.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 8
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: hm_net
epoch: 300
folderData: assignment1_data
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-14-03-25-20
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
HM_Net(
  (conv1): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv2): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv3): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv4): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv5): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
train >>> epoch: 1/300, batch: 1/14, mean_loss: 617286.0771
train >>> epoch: 1/300, batch: 2/14, mean_loss: 616358.7951
train >>> epoch: 1/300, batch: 3/14, mean_loss: 615397.3526
train >>> epoch: 1/300, batch: 4/14, mean_loss: 614448.8283
train >>> epoch: 1/300, batch: 5/14, mean_loss: 613502.3628
train >>> epoch: 1/300, batch: 6/14, mean_loss: 612519.1770
train >>> epoch: 1/300, batch: 7/14, mean_loss: 611450.3884
train >>> epoch: 1/300, batch: 8/14, mean_loss: 610294.1174
train >>> epoch: 1/300, batch: 9/14, mean_loss: 609103.7285
train >>> epoch: 1/300, batch: 10/14, mean_loss: 607809.7296
train >>> epoch: 1/300, batch: 11/14, mean_loss: 605853.4445
train >>> epoch: 1/300, batch: 12/14, mean_loss: 604237.9296
train >>> epoch: 1/300, batch: 13/14, mean_loss: 600433.5062
train >>> epoch: 1/300, batch: 14/14, mean_loss: 562683.3040
2740.128868283089
685.0106928368396
valid >>> epoch: 1/300, mean_loss: 1712.5698
criteria decreased from inf to 1712.5698, saving best model at D:\Data\cs-8395-dl\model\2020-01-14-03-25-20\2020-01-14-03-25-20_hm_net_best.pt
train >>> epoch: 2/300, batch: 1/14, mean_loss: 558897.7868
train >>> epoch: 2/300, batch: 2/14, mean_loss: 529638.2073
train >>> epoch: 2/300, batch: 3/14, mean_loss: 479900.9423
train >>> epoch: 2/300, batch: 4/14, mean_loss: 417618.0502
train >>> epoch: 2/300, batch: 5/14, mean_loss: 384573.5296
train >>> epoch: 2/300, batch: 6/14, mean_loss: 328289.5980
train >>> epoch: 2/300, batch: 7/14, mean_loss: 288259.3486
train >>> epoch: 2/300, batch: 8/14, mean_loss: 254307.1043
train >>> epoch: 2/300, batch: 9/14, mean_loss: 226647.1059
train >>> epoch: 2/300, batch: 10/14, mean_loss: 204728.5300
train >>> epoch: 2/300, batch: 11/14, mean_loss: 186117.1560
train >>> epoch: 2/300, batch: 12/14, mean_loss: 170607.6098
train >>> epoch: 2/300, batch: 13/14, mean_loss: 157483.9514
train >>> epoch: 2/300, batch: 14/14, mean_loss: 146238.3294
642.893426100567
160.05644622956152
valid >>> epoch: 2/300, mean_loss: 401.4749
criteria decreased from 1712.5698 to 401.4749, saving best model at D:\Data\cs-8395-dl\model\2020-01-14-03-25-20\2020-01-14-03-25-20_hm_net_best.pt
train >>> epoch: 3/300, batch: 1/14, mean_loss: 0.0950

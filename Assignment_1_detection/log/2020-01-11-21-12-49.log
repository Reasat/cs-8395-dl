2020-01-11-21-12-49
train.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 32
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: resnet18
epoch: 1000
folderData: assignment1_data
lr: 1e-05
resume_from: D:\Data\cs-8395-dl\model\2020-01-11-16-32-29\2020-01-11-16-32-29_resnet18_best.pt
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-11-21-12-49
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
ResNet18(
  (resnet18): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer2): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer3): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (layer4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
    (fc): Linear(in_features=512, out_features=1000, bias=True)
  )
  (resnet18_fc_stripped): Sequential(
    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (8): AdaptiveAvgPool2d(output_size=(1, 1))
  )
  (fc1): Linear(in_features=512, out_features=2, bias=True)
)
resuming training from D:\Data\cs-8395-dl\model\2020-01-11-16-32-29\2020-01-11-16-32-29_resnet18_best.pt
train >>> epoch: 532/1531, batch: 1/4, mean_loss: 0.0260
train >>> epoch: 532/1531, batch: 2/4, mean_loss: 2.3134
train >>> epoch: 532/1531, batch: 3/4, mean_loss: 2.0566
train >>> epoch: 532/1531, batch: 4/4, mean_loss: 1.6889
1172.2210693359375
valid >>> epoch: 532/1531, mean_loss: 1172.2211
train >>> epoch: 533/1531, batch: 1/4, mean_loss: 0.5329
train >>> epoch: 533/1531, batch: 2/4, mean_loss: 0.4398
train >>> epoch: 533/1531, batch: 3/4, mean_loss: 0.3665
train >>> epoch: 533/1531, batch: 4/4, mean_loss: 0.3015
1565.5777587890625
valid >>> epoch: 533/1531, mean_loss: 1565.5778
train >>> epoch: 534/1531, batch: 1/4, mean_loss: 0.1088
train >>> epoch: 534/1531, batch: 2/4, mean_loss: 0.1090
train >>> epoch: 534/1531, batch: 3/4, mean_loss: 0.0980
train >>> epoch: 534/1531, batch: 4/4, mean_loss: 0.1018
642.5540161132812
valid >>> epoch: 534/1531, mean_loss: 642.5540
train >>> epoch: 535/1531, batch: 1/4, mean_loss: 0.0623
train >>> epoch: 535/1531, batch: 2/4, mean_loss: 0.0728
train >>> epoch: 535/1531, batch: 3/4, mean_loss: 0.0771
train >>> epoch: 535/1531, batch: 4/4, mean_loss: 0.0814
627.7460327148438
valid >>> epoch: 535/1531, mean_loss: 627.7460
train >>> epoch: 536/1531, batch: 1/4, mean_loss: 0.0834
train >>> epoch: 536/1531, batch: 2/4, mean_loss: 0.0690
train >>> epoch: 536/1531, batch: 3/4, mean_loss: 0.0677
train >>> epoch: 536/1531, batch: 4/4, mean_loss: 0.0643
210.47947692871094
valid >>> epoch: 536/1531, mean_loss: 210.4795
train >>> epoch: 537/1531, batch: 1/4, mean_loss: 0.0523
train >>> epoch: 537/1531, batch: 2/4, mean_loss: 0.0567
train >>> epoch: 537/1531, batch: 3/4, mean_loss: 0.0605
train >>> epoch: 537/1531, batch: 4/4, mean_loss: 0.0617
28.905750274658203
valid >>> epoch: 537/1531, mean_loss: 28.9058
train >>> epoch: 538/1531, batch: 1/4, mean_loss: 0.0574
train >>> epoch: 538/1531, batch: 2/4, mean_loss: 0.0512
train >>> epoch: 538/1531, batch: 3/4, mean_loss: 0.0512
train >>> epoch: 538/1531, batch: 4/4, mean_loss: 0.0494
1.3897085189819336
valid >>> epoch: 538/1531, mean_loss: 1.3897
train >>> epoch: 539/1531, batch: 1/4, mean_loss: 0.0429
train >>> epoch: 539/1531, batch: 2/4, mean_loss: 0.0533
train >>> epoch: 539/1531, batch: 3/4, mean_loss: 0.0532
train >>> epoch: 539/1531, batch: 4/4, mean_loss: 0.0533
0.21900251507759094
valid >>> epoch: 539/1531, mean_loss: 0.2190
train >>> epoch: 540/1531, batch: 1/4, mean_loss: 0.0381
train >>> epoch: 540/1531, batch: 2/4, mean_loss: 0.0338
train >>> epoch: 540/1531, batch: 3/4, mean_loss: 0.0393
train >>> epoch: 540/1531, batch: 4/4, mean_loss: 0.0363
0.3060638904571533
valid >>> epoch: 540/1531, mean_loss: 0.3061
train >>> epoch: 541/1531, batch: 1/4, mean_loss: 0.0388
train >>> epoch: 541/1531, batch: 2/4, mean_loss: 0.0367
train >>> epoch: 541/1531, batch: 3/4, mean_loss: 0.0322
train >>> epoch: 541/1531, batch: 4/4, mean_loss: 0.0371
0.10625176876783371
valid >>> epoch: 541/1531, mean_loss: 0.1063
train >>> epoch: 542/1531, batch: 1/4, mean_loss: 0.0250
train >>> epoch: 542/1531, batch: 2/4, mean_loss: 0.0224
train >>> epoch: 542/1531, batch: 3/4, mean_loss: 0.0218
train >>> epoch: 542/1531, batch: 4/4, mean_loss: 0.0236
0.11675893515348434
valid >>> epoch: 542/1531, mean_loss: 0.1168
train >>> epoch: 543/1531, batch: 1/4, mean_loss: 0.0110
train >>> epoch: 543/1531, batch: 2/4, mean_loss: 0.0157
train >>> epoch: 543/1531, batch: 3/4, mean_loss: 0.0185
train >>> epoch: 543/1531, batch: 4/4, mean_loss: 0.0245
0.11653002351522446
valid >>> epoch: 543/1531, mean_loss: 0.1165
train >>> epoch: 544/1531, batch: 1/4, mean_loss: 0.0090
train >>> epoch: 544/1531, batch: 2/4, mean_loss: 0.0120
train >>> epoch: 544/1531, batch: 3/4, mean_loss: 0.0144
train >>> epoch: 544/1531, batch: 4/4, mean_loss: 0.0208
0.11949314922094345
valid >>> epoch: 544/1531, mean_loss: 0.1195
train >>> epoch: 545/1531, batch: 1/4, mean_loss: 0.0135
train >>> epoch: 545/1531, batch: 2/4, mean_loss: 0.0190
train >>> epoch: 545/1531, batch: 3/4, mean_loss: 0.0166
train >>> epoch: 545/1531, batch: 4/4, mean_loss: 0.0192
0.07662323862314224
valid >>> epoch: 545/1531, mean_loss: 0.0766
criteria decreased from 0.0864 to 0.0766, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-21-12-49\2020-01-11-21-12-49_resnet18_best.pt
train >>> epoch: 546/1531, batch: 1/4, mean_loss: 0.0088
train >>> epoch: 546/1531, batch: 2/4, mean_loss: 0.0108
train >>> epoch: 546/1531, batch: 3/4, mean_loss: 0.0168
train >>> epoch: 546/1531, batch: 4/4, mean_loss: 0.0187
0.056179847568273544
valid >>> epoch: 546/1531, mean_loss: 0.0562
criteria decreased from 0.0766 to 0.0562, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-21-12-49\2020-01-11-21-12-49_resnet18_best.pt
train >>> epoch: 547/1531, batch: 1/4, mean_loss: 0.0146
train >>> epoch: 547/1531, batch: 2/4, mean_loss: 0.0142
train >>> epoch: 547/1531, batch: 3/4, mean_loss: 0.0122
train >>> epoch: 547/1531, batch: 4/4, mean_loss: 0.0150
0.055252671241760254
valid >>> epoch: 547/1531, mean_loss: 0.0553
criteria decreased from 0.0562 to 0.0553, saving best model at D:\Data\cs-8395-dl\model\2020-01-11-21-12-49\2020-01-11-21-12-49_resnet18_best.pt
train >>> epoch: 548/1531, batch: 1/4, mean_loss: 0.0143
train >>> epoch: 548/1531, batch: 2/4, mean_loss: 0.0125

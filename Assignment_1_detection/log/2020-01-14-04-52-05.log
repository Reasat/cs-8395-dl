2020-01-14-04-52-05
train_hm.py
--------------------------------------------------------------------------------------------------------------------
alpha: 0.7
batchSize: 16
bottleneckFeatures: 0
dir_lf: D:\Data\cs-8395-dl
dir_project: C:\Users\Reasat\Projects\cs-8395-dl\Assignment_1_detection
encoder: hm_net
epoch: 100
folderData: assignment1_data
gamma: 2
lr: 0.001
resume_from: None
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-01-14-04-52-05
loading images to RAM
train samples 105
loading images to RAM
validation samples 10
HM_Net(
  (conv1): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv2): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv3): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv4): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (conv5): conv_bn_3x3(
    (block): Sequential(
      (0): Conv2d(8, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (1): ReLU()
      (2): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
)
tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0020, 0.0021, 0.0021,  ..., 0.0000, 0.0000, 0.0000],
         [0.0019, 0.0019, 0.0019,  ..., 0.0000, 0.0000, 0.0000],
         [0.0018, 0.0018, 0.0018,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        ...,

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],

        [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         ...,
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],
         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],
       device='cuda:0', dtype=torch.float64) tensor([[[[-2.0278e-01, -2.0278e-01, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01, -1.6832e-01],
          [-2.0278e-01, -2.0278e-01, -2.0278e-01,  ...,  8.1252e-02,
            4.4923e-01,  5.5042e-01],
          [-2.0278e-01, -2.0278e-01, -2.0278e-01,  ..., -1.5709e-01,
           -4.0769e-02,  2.7009e-01],
          ...,
          [-2.0278e-01, -2.2716e-02,  2.6244e-01,  ..., -2.0278e-01,
            1.4720e-01,  2.0697e-01],
          [-1.7691e-01,  4.0324e-02,  4.4742e-01,  ...,  1.0756e-02,
           -2.0278e-01, -1.1107e-02],
          [ 1.2156e-01, -2.0278e-01,  1.2308e-03,  ..., -2.0278e-01,
           -1.4464e-01,  1.0225e-02]]],


        [[[-2.0278e-01, -2.0278e-01, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01,  7.4939e-01],
          [-2.0278e-01, -2.0278e-01, -1.3262e-01,  ...,  2.1988e+00,
            1.2574e+00,  2.4169e+00],
          [-2.0278e-01, -2.0278e-01, -2.0278e-01,  ..., -2.0278e-01,
           -1.8533e-01,  8.0329e-01],
          ...,
          [ 1.6009e-01, -6.7603e-02, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01, -5.7097e-02],
          [-2.0278e-01,  5.9160e-01,  4.4854e-01,  ...,  2.6178e-01,
           -2.0278e-01, -2.0278e-01],
          [-1.6262e-01, -1.6362e-01, -2.0278e-01,  ..., -1.2444e-01,
           -2.0278e-01, -2.0278e-01]]],


        [[[ 1.5353e-01,  4.4501e-01, -2.0278e-01,  ..., -2.0278e-01,
            4.8956e-01,  1.8207e+00],
          [-1.0383e-02,  3.8127e-01,  1.1259e-01,  ..., -2.0278e-01,
           -1.0082e-01,  8.8821e-01],
          [-1.3350e-02,  5.1646e-01,  8.0224e-01,  ..., -2.0278e-01,
           -2.0278e-01, -2.0278e-01],
          ...,
          [ 1.7794e-01,  1.5755e-01, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01, -6.0611e-02],
          [-2.0278e-01,  1.0586e+00,  2.3760e-01,  ..., -2.0278e-01,
           -2.0278e-01, -5.2643e-02],
          [-1.0366e-01, -2.0278e-01, -2.0278e-01,  ..., -1.1771e-01,
           -2.0278e-01, -2.0278e-01]]],


        ...,


        [[[-1.3294e-01, -2.0278e-01, -2.7379e-02,  ..., -1.8593e-02,
           -2.0278e-01,  6.2122e-02],
          [-2.0278e-01, -2.0278e-01,  1.0361e-01,  ..., -2.0278e-01,
           -2.0278e-01,  5.3397e-02],
          [-2.0278e-01, -2.0278e-01, -2.0278e-01,  ...,  9.0583e-02,
            2.4897e-01,  9.7855e-03],
          ...,
          [-2.0278e-01, -8.5114e-02,  5.5782e-01,  ..., -7.6872e-02,
            1.0390e-01,  2.0083e-01],
          [-1.7689e-01,  5.4974e-02,  3.5286e-01,  ...,  1.7422e-01,
           -2.0278e-01,  2.2417e-01],
          [ 1.0626e-01, -2.0278e-01,  1.1246e-02,  ..., -5.0639e-02,
           -4.0423e-02,  4.0918e-02]]],


        [[[ 9.3416e-02,  3.7200e-01, -2.0278e-01,  ..., -2.0278e-01,
            7.8996e-01,  2.2185e+00],
          [ 2.5969e-03,  3.0365e-01, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01,  1.0080e+00],
          [-3.6156e-02,  1.8236e-01,  5.2116e-01,  ..., -2.0278e-01,
           -2.0278e-01, -2.0278e-01],
          ...,
          [ 1.5859e-01, -1.6048e-01, -1.6803e-01,  ..., -2.0278e-01,
           -2.0278e-01,  6.4652e-02],
          [-2.0278e-01,  5.8844e-01,  6.4014e-01,  ..., -2.0278e-01,
           -2.0278e-01,  1.2809e-01],
          [-5.2291e-02, -6.8758e-02, -2.0278e-01,  ..., -2.0278e-01,
           -2.0278e-01, -2.0278e-01]]],


        [[[-2.0278e-01, -2.0278e-01, -2.0278e-01,  ...,  8.9340e-02,
           -2.0278e-01, -2.0278e-01],
          [-2.0278e-01, -2.0278e-01, -2.0278e-01,  ...,  9.4914e-01,
            1.7707e+00,  2.0809e+00],
          [-2.0278e-01, -2.0278e-01, -1.0667e-01,  ..., -2.0278e-01,
           -2.0278e-01,  6.1702e-01],
          ...,
          [ 3.4975e-01, -2.0278e-01, -2.0616e-02,  ...,  4.2831e-01,
           -2.0278e-01, -1.1310e-01],
          [ 9.3662e-02,  1.3229e-01,  1.2959e-01,  ...,  1.5454e+00,
           -1.8310e-01, -2.0278e-01],
          [-2.0194e-01,  1.8980e-01, -2.3427e-02,  ..., -2.0278e-01,
           -2.0278e-01, -2.0278e-01]]]], device='cuda:0', dtype=torch.float64,
       grad_fn=<CopyBackwards>)
train >>> epoch: 1/100, batch: 1/7, mean_loss: nan
tensor([[[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        ...,

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]],

        [[0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         ...,
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.],
         [0., 0., 0.,  ..., 0., 0., 0.]]], device='cuda:0',
       dtype=torch.float64) tensor([[[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        ...,


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]],


        [[[nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          ...,
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan],
          [nan, nan, nan,  ..., nan, nan, nan]]]], device='cuda:0',
       dtype=torch.float64, grad_fn=<CopyBackwards>)
train >>> epoch: 1/100, batch: 2/7, mean_loss: nan

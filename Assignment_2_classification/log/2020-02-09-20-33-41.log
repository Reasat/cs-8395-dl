2020-02-09-20-33-41
train_bs.py
--------------------------------------------------------------------------------------------------------------------
batchSize: 14
bottleneckFeatures: 0
brightness: [-0.2, 0.2]
contrast: [-0.2, 0.2]
dir_lf: D:\Data\cs-8395-dl
dir_project: ..
encoder: resnet18
epoch: 20
folderData: assignment2_data
lr: 0.001
overrideLR: 1
resize: 256
resume_from: None
to_ram: 0
--------------------------------------------------------------------------------------------------------------------
creating directory to save model at D:\Data\cs-8395-dl\model\2020-02-09-20-33-41
balanced_max:  6130
number of samples in balanced dataset 42910
train samples 9015
validation samples 1000
ISIC_0031180
ISIC_0027204
ISIC_0026511
ISIC_0031344
ISIC_0027577
ISIC_0025731
ISIC_0032076
ISIC_0028604
ISIC_0024732
ISIC_0029288
ISIC_0027188
ISIC_0026729
ISIC_0024504
ISIC_0028146
train >>> epoch: 1/20, batch: 1/643, mean_loss: 2.1705, mean_acc: 0.0000
ISIC_0028879
ISIC_0032396
ISIC_0028622
ISIC_0027745
ISIC_0028517
ISIC_0025691
ISIC_0028714
ISIC_0030358
ISIC_0028029
ISIC_0028701
ISIC_0027626
ISIC_0031108
ISIC_0024590
ISIC_0025873
train >>> epoch: 1/20, batch: 2/643, mean_loss: 1.9838, mean_acc: 0.2143
ISIC_0027999
ISIC_0027190
ISIC_0026085
ISIC_0025373
ISIC_0029309
ISIC_0026760
ISIC_0024867
ISIC_0025119
ISIC_0030192
ISIC_0025032
ISIC_0030244
ISIC_0031044
ISIC_0026978
ISIC_0029608
train >>> epoch: 1/20, batch: 3/643, mean_loss: 1.7844, mean_acc: 0.3095
ISIC_0028277
ISIC_0028109
ISIC_0026290
ISIC_0029824
ISIC_0026927
ISIC_0030712
ISIC_0027665
ISIC_0027873
ISIC_0032790
ISIC_0030630
ISIC_0025223
ISIC_0025790
ISIC_0024595
ISIC_0024747
train >>> epoch: 1/20, batch: 4/643, mean_loss: 1.8347, mean_acc: 0.2857
ISIC_0029604
ISIC_0025265
ISIC_0031349
ISIC_0026417
ISIC_0026014
ISIC_0027057
ISIC_0028431
ISIC_0029306
ISIC_0024864
ISIC_0026273
ISIC_0031002
ISIC_0026040
ISIC_0031009
ISIC_0030606
train >>> epoch: 1/20, batch: 5/643, mean_loss: 1.7587, mean_acc: 0.3286
ISIC_0032647
ISIC_0028288
ISIC_0028258
ISIC_0025373
ISIC_0027958
ISIC_0026970
ISIC_0030606
ISIC_0031432
ISIC_0027872
ISIC_0026663
ISIC_0029973
ISIC_0028730
ISIC_0027004
ISIC_0025606
train >>> epoch: 1/20, batch: 6/643, mean_loss: 1.8295, mean_acc: 0.3095
ISIC_0030299
ISIC_0030950
ISIC_0032826
ISIC_0030555
ISIC_0031211
ISIC_0027371
ISIC_0029099
ISIC_0029373
ISIC_0030192
ISIC_0031897
ISIC_0029052
ISIC_0025577
ISIC_0026760
ISIC_0031759
train >>> epoch: 1/20, batch: 7/643, mean_loss: 1.8477, mean_acc: 0.3163
ISIC_0024954
ISIC_0032968
ISIC_0028958
ISIC_0027626
ISIC_0025130
ISIC_0024564
ISIC_0031648
ISIC_0032789
ISIC_0031295
ISIC_0026842
ISIC_0031429
ISIC_0024843
ISIC_0029352
ISIC_0030722
train >>> epoch: 1/20, batch: 8/643, mean_loss: 1.9838, mean_acc: 0.2946
ISIC_0030908
ISIC_0024767
ISIC_0028881
ISIC_0029824
ISIC_0024710
ISIC_0027609
ISIC_0025677
ISIC_0027816
ISIC_0025963
ISIC_0029687
ISIC_0025314
ISIC_0030297
ISIC_0029917
ISIC_0025924
train >>> epoch: 1/20, batch: 9/643, mean_loss: 2.0009, mean_acc: 0.2937
ISIC_0030859
ISIC_0025543
ISIC_0032534
ISIC_0029052
ISIC_0031191
ISIC_0031712
ISIC_0027563
ISIC_0026542
ISIC_0032750
ISIC_0031707
ISIC_0029248
ISIC_0026549
ISIC_0026988
ISIC_0025606
train >>> epoch: 1/20, batch: 10/643, mean_loss: 1.9538, mean_acc: 0.3071
ISIC_0025570
ISIC_0028103
ISIC_0030172
ISIC_0027044
ISIC_0031292
ISIC_0028168
ISIC_0033123
ISIC_0028527
ISIC_0024482
ISIC_0029764
ISIC_0025504
ISIC_0026319
ISIC_0030813
ISIC_0031276
train >>> epoch: 1/20, batch: 11/643, mean_loss: 1.9262, mean_acc: 0.3117
ISIC_0025878
ISIC_0032182
ISIC_0026523
ISIC_0029578
ISIC_0030549
ISIC_0031585
ISIC_0032545
ISIC_0029114
ISIC_0030171
ISIC_0024740
ISIC_0032613
ISIC_0031040
ISIC_0029919
ISIC_0026163
train >>> epoch: 1/20, batch: 12/643, mean_loss: 1.9210, mean_acc: 0.3095
ISIC_0028278
ISIC_0028445
ISIC_0032498
ISIC_0031309
ISIC_0029315
ISIC_0025630
ISIC_0033158
ISIC_0026822
ISIC_0027822
ISIC_0027513
ISIC_0029248
ISIC_0025808
ISIC_0026074
ISIC_0026693
train >>> epoch: 1/20, batch: 13/643, mean_loss: 1.8754, mean_acc: 0.3242
ISIC_0026925
ISIC_0026207
ISIC_0030316
ISIC_0025504
ISIC_0027343
ISIC_0024403
ISIC_0033092
ISIC_0024563
ISIC_0032617
ISIC_0024623
ISIC_0030757
ISIC_0027884
ISIC_0026952
ISIC_0027983
train >>> epoch: 1/20, batch: 14/643, mean_loss: 1.9260, mean_acc: 0.3163
ISIC_0030125
ISIC_0032925
ISIC_0028970
ISIC_0028735
ISIC_0025948
ISIC_0027631
ISIC_0029439
ISIC_0026509
ISIC_0029630
ISIC_0028503
ISIC_0031457
ISIC_0032404
ISIC_0032290
ISIC_0026467
train >>> epoch: 1/20, batch: 15/643, mean_loss: 1.8887, mean_acc: 0.3238
ISIC_0025220
ISIC_0026976
ISIC_0032618
ISIC_0031457
ISIC_0028224
ISIC_0025826
ISIC_0032270
ISIC_0029066
ISIC_0032626
ISIC_0024381
ISIC_0030427
ISIC_0028372
ISIC_0032429
ISIC_0025707
train >>> epoch: 1/20, batch: 16/643, mean_loss: 1.8455, mean_acc: 0.3304
ISIC_0026217
ISIC_0027065
ISIC_0027367
ISIC_0025504
ISIC_0030036
ISIC_0027297
ISIC_0024706
ISIC_0029684
ISIC_0031586
ISIC_0032654
ISIC_0032247
ISIC_0025411
ISIC_0030339
ISIC_0029742
train >>> epoch: 1/20, batch: 17/643, mean_loss: 1.8219, mean_acc: 0.3487
ISIC_0027906
ISIC_0030689
ISIC_0030801
ISIC_0025373
ISIC_0030191
ISIC_0027058
ISIC_0029486
ISIC_0026197
ISIC_0027174
ISIC_0033124
ISIC_0031271
ISIC_0028335
ISIC_0032461
ISIC_0028188
train >>> epoch: 1/20, batch: 18/643, mean_loss: 1.8155, mean_acc: 0.3492
ISIC_0031725
ISIC_0030575
ISIC_0030377
ISIC_0025504
ISIC_0027303
ISIC_0031009
ISIC_0030070
ISIC_0026577
ISIC_0026558
ISIC_0031125
ISIC_0025903
ISIC_0033151
ISIC_0028329
ISIC_0026068
train >>> epoch: 1/20, batch: 19/643, mean_loss: 1.8065, mean_acc: 0.3496
ISIC_0032122
ISIC_0033287
ISIC_0030561
ISIC_0028790
ISIC_0031929
ISIC_0029899
ISIC_0025707
ISIC_0033115
ISIC_0032662
ISIC_0030173
ISIC_0031002
ISIC_0028372
ISIC_0032461
ISIC_0028188
train >>> epoch: 1/20, batch: 20/643, mean_loss: 1.8095, mean_acc: 0.3500
ISIC_0027429
ISIC_0025324
ISIC_0032325
ISIC_0029824
ISIC_0032199
ISIC_0025971
ISIC_0031093
ISIC_0026470
ISIC_0032182
ISIC_0031686
ISIC_0029824
ISIC_0029715
ISIC_0029820
ISIC_0027937
train >>> epoch: 1/20, batch: 21/643, mean_loss: 1.7937, mean_acc: 0.3435
ISIC_0026887
ISIC_0031013
ISIC_0029202
ISIC_0029783
ISIC_0026702
ISIC_0026760
ISIC_0031093
ISIC_0032292
ISIC_0025941
ISIC_0029455
ISIC_0031002
ISIC_0028224
ISIC_0031298
ISIC_0032614
train >>> epoch: 1/20, batch: 22/643, mean_loss: 1.7981, mean_acc: 0.3409
ISIC_0033097
ISIC_0032888
ISIC_0030768
ISIC_0028926
ISIC_0031012
ISIC_0026845
ISIC_0025807
ISIC_0028405
ISIC_0026266
ISIC_0030172
ISIC_0027141
ISIC_0033084
ISIC_0026845
ISIC_0027563
train >>> epoch: 1/20, batch: 23/643, mean_loss: 1.7738, mean_acc: 0.3509
ISIC_0031418
ISIC_0026236
ISIC_0024408
ISIC_0028926
ISIC_0029573
ISIC_0030261
ISIC_0031759
ISIC_0030865
ISIC_0025277
ISIC_0027142
ISIC_0028735
ISIC_0027650
ISIC_0029602
ISIC_0027937
train >>> epoch: 1/20, batch: 24/643, mean_loss: 1.7601, mean_acc: 0.3542
ISIC_0029038
ISIC_0030150
ISIC_0025837
ISIC_0031002
ISIC_0028517
ISIC_0025417
ISIC_0032270
ISIC_0028273
ISIC_0028086
ISIC_0026153
ISIC_0027626
ISIC_0026194
ISIC_0024454
ISIC_0031648
train >>> epoch: 1/20, batch: 25/643, mean_loss: 1.7347, mean_acc: 0.3629
ISIC_0028799
ISIC_0025531
ISIC_0031277
ISIC_0025154
ISIC_0031927
ISIC_0028583
ISIC_0028188
ISIC_0033221
ISIC_0033074
ISIC_0030458
ISIC_0027107
ISIC_0025182
ISIC_0031976
ISIC_0025873
train >>> epoch: 1/20, batch: 26/643, mean_loss: 1.7193, mean_acc: 0.3681
ISIC_0030809
ISIC_0032626
